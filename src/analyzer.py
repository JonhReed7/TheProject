"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏.
"""
import re
from dataclasses import dataclass
from typing import Optional

from .metrics import (
    flesch_reading_ease,
    coleman_liau_index,
    automated_readability_index,
    count_syllables,
    count_syllables_ru
)


@dataclass
class ReadabilityResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏."""
    text_length: int
    word_count: int
    sentence_count: int
    avg_word_length: float
    avg_sentence_length: float
    flesch_score: float
    coleman_liau: float
    ari: float
    difficulty_level: str
    target_audience: str
    recommendations: list


class TextAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞."""
    
    DIFFICULTY_LEVELS = {
        (90, 100): ("–û—á–µ–Ω—å –ª–µ–≥–∫–æ", "–ù–∞—á–∞–ª—å–Ω–∞—è —à–∫–æ–ª–∞ (1-4 –∫–ª–∞—Å—Å)"),
        (70, 89): ("–õ–µ–≥–∫–æ", "–°—Ä–µ–¥–Ω—è—è —à–∫–æ–ª–∞ (5-7 –∫–ª–∞—Å—Å)"),
        (50, 69): ("–°—Ä–µ–¥–Ω–µ", "–°—Ç–∞—Ä—à–∞—è —à–∫–æ–ª–∞ (8-11 –∫–ª–∞—Å—Å)"),
        (30, 49): ("–°–ª–æ–∂–Ω–æ", "–°—Ç—É–¥–µ–Ω—Ç—ã –±–∞–∫–∞–ª–∞–≤—Ä–∏–∞—Ç–∞"),
        (0, 29): ("–û—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ", "–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞ / –°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã"),
    }
    
    def __init__(self, language: str = "en"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.
        
        Args:
            language: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ ('en' –∏–ª–∏ 'ru')
        """
        self.language = language
        self._syllable_counter = count_syllables_ru if language == "ru" else count_syllables
    
    def _tokenize_sentences(self, text: str) -> list:
        """–†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è."""
        sentences = re.split(r'[.!?]+', text)
        return [s.strip() for s in sentences if s.strip()]
    
    def _tokenize_words(self, text: str) -> list:
        """–†–∞–∑–±–∏–≤–∫–∞ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–ª–æ–≤–∞."""
        words = re.findall(r'\b\w+\b', text.lower())
        return words
    
    def _count_characters(self, words: list) -> int:
        """–ü–æ–¥—Å—á—ë—Ç –±—É–∫–≤ (–±–µ–∑ –ø—Ä–æ–±–µ–ª–æ–≤ –∏ –∑–Ω–∞–∫–æ–≤)."""
        return sum(len(word) for word in words)
    
    def _count_total_syllables(self, words: list) -> int:
        """–ü–æ–¥—Å—á—ë—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≥–æ–≤."""
        return sum(self._syllable_counter(word) for word in words)
    
    def _get_difficulty_level(self, flesch_score: float) -> tuple:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É –§–ª–µ—à–∞."""
        for (low, high), (level, audience) in self.DIFFICULTY_LEVELS.items():
            if low <= flesch_score <= high:
                return level, audience
        return "–ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def _generate_recommendations(self, result: dict) -> list:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —Ç–µ–∫—Å—Ç–∞."""
        recommendations = []
        
        if result["avg_sentence_length"] > 25:
            recommendations.append(
                "üìù –°–æ–∫—Ä–∞—Ç–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è: —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ > 25 —Å–ª–æ–≤. "
                "–†–∞–∑–±–µ–π—Ç–µ –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –∫–æ—Ä–æ—Ç–∫–∏–µ."
            )
        
        if result["avg_word_length"] > 6:
            recommendations.append(
                "üìñ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞: —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ > 6 –±—É–∫–≤. "
                "–ó–∞–º–µ–Ω–∏—Ç–µ —Å–ª–æ–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –Ω–∞ –ø—Ä–æ—Å—Ç—ã–µ —Å–∏–Ω–æ–Ω–∏–º—ã."
            )
        
        if result["flesch_score"] < 30:
            recommendations.append(
                "‚ö†Ô∏è –¢–µ–∫—Å—Ç –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã–π –¥–ª—è –≤–æ—Å–ø—Ä–∏—è—Ç–∏—è. "
                "–î–æ–±–∞–≤—å—Ç–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è –∏ –ø—Ä–∏–º–µ—Ä—ã."
            )
        
        if not recommendations:
            recommendations.append("‚úÖ –¢–µ–∫—Å—Ç —Ö–æ—Ä–æ—à–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω!")
        
        return recommendations
    
    def analyze(self, text: str) -> ReadabilityResult:
        """
        –ê–Ω–∞–ª–∏–∑ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            ReadabilityResult —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
        """
        if not text or not text.strip():
            raise ValueError("–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        sentences = self._tokenize_sentences(text)
        words = self._tokenize_words(text)
        
        if len(words) < 10:
            raise ValueError("–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π (–º–∏–Ω–∏–º—É–º 10 —Å–ª–æ–≤)")
        
        total_chars = self._count_characters(words)
        total_syllables = self._count_total_syllables(words)
        
        word_count = len(words)
        sentence_count = max(1, len(sentences))
        
        avg_word_length = round(total_chars / word_count, 2)
        avg_sentence_length = round(word_count / sentence_count, 2)
        
        flesch = flesch_reading_ease(word_count, sentence_count, total_syllables)
        coleman = coleman_liau_index(total_chars, word_count, sentence_count)
        ari = automated_readability_index(total_chars, word_count, sentence_count)
        
        difficulty, audience = self._get_difficulty_level(flesch)
        
        intermediate = {
            "avg_sentence_length": avg_sentence_length,
            "avg_word_length": avg_word_length,
            "flesch_score": flesch,
        }
        recommendations = self._generate_recommendations(intermediate)
        
        return ReadabilityResult(
            text_length=len(text),
            word_count=word_count,
            sentence_count=sentence_count,
            avg_word_length=avg_word_length,
            avg_sentence_length=avg_sentence_length,
            flesch_score=flesch,
            coleman_liau=coleman,
            ari=ari,
            difficulty_level=difficulty,
            target_audience=audience,
            recommendations=recommendations
        )
    
    def analyze_file(self, filepath: str) -> ReadabilityResult:
        """–ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞."""
        with open(filepath, 'r', encoding='utf-8') as f:
            text = f.read()
        return self.analyze(text)