"""
–ì–ª–∞–≤–Ω—ã–π –º–æ–¥—É–ª—å –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞.

–°–æ–¥–µ—Ä–∂–∏—Ç –∫–ª–∞—Å—Å TextAnalyzer –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
—á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.
"""

import re
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any

from .metrics import (
    flesch_reading_ease,
    flesch_kincaid_grade,
    coleman_liau_index,
    automated_readability_index,
    smog_index,
    count_syllables,
    count_syllables_ru,
    get_grade_description
)
from .utils import (
    tokenize_sentences,
    tokenize_words,
    count_characters,
    clean_text,
    detect_language,
    read_text_file,
    format_result_as_markdown,
    format_result_as_dict
)


@dataclass
class ReadabilityResult:
    """
    –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞.
    
    Attributes:
        text_length: –î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ –≤ —Å–∏–º–≤–æ–ª–∞—Ö
        word_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
        sentence_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        avg_word_length: –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞ –≤ –±—É–∫–≤–∞—Ö
        avg_sentence_length: –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ö
        flesch_score: –ò–Ω–¥–µ–∫—Å —É–¥–æ–±–æ—á–∏—Ç–∞–µ–º–æ—Å—Ç–∏ –§–ª–µ—à–∞ (0-100)
        flesch_kincaid: –£—Ä–æ–≤–µ–Ω—å –∫–ª–∞—Å—Å–∞ –ø–æ –§–ª–µ—à—É-–ö–∏–Ω–∫–µ–π–¥—É
        coleman_liau: –ò–Ω–¥–µ–∫—Å –ö–æ—É–ª–º–∞–Ω–∞-–õ–∏–∞—É
        ari: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∏–Ω–¥–µ–∫—Å —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏
        difficulty_level: –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (—Ç–µ–∫—Å—Ç–æ–≤–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ)
        target_audience: –¶–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è
        recommendations: –°–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é
    """
    text_length: int
    word_count: int
    sentence_count: int
    avg_word_length: float
    avg_sentence_length: float
    flesch_score: float
    flesch_kincaid: float
    coleman_liau: float
    ari: float
    difficulty_level: str
    target_audience: str
    recommendations: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ —Å–ª–æ–≤–∞—Ä—å."""
        return format_result_as_dict(self)
    
    def to_markdown(self, title: str = "Analysis Result") -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –≤ Markdown."""
        return format_result_as_markdown(self, title)
    
    def __str__(self) -> str:
        """–°—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞."""
        return (
            f"ReadabilityResult(\n"
            f"  words={self.word_count}, "
            f"sentences={self.sentence_count},\n"
            f"  flesch={self.flesch_score}, "
            f"difficulty='{self.difficulty_level}',\n"
            f"  audience='{self.target_audience}'\n"
            f")"
        )


class TextAnalyzer:
    """
    –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞.
    
    –í—ã—á–∏—Å–ª—è–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç
    —Ü–µ–ª–µ–≤—É—é –∞—É–¥–∏—Ç–æ—Ä–∏—é –¥–ª—è —É—á–µ–±–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤.
    
    Attributes:
        language: –Ø–∑—ã–∫ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ ('en' –∏–ª–∏ 'ru')
        
    Examples:
        >>> analyzer = TextAnalyzer(language='en')
        >>> result = analyzer.analyze("The cat sat on the mat.")
        >>> print(result.difficulty_level)
        '–û—á–µ–Ω—å –ª–µ–≥–∫–æ'
    """
    
    # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É –§–ª–µ—à–∞
    DIFFICULTY_THRESHOLDS = {
        (90, 100): ("–û—á–µ–Ω—å –ª–µ–≥–∫–æ", "–ù–∞—á–∞–ª—å–Ω–∞—è —à–∫–æ–ª–∞ (1-4 –∫–ª–∞—Å—Å)"),
        (70, 89): ("–õ–µ–≥–∫–æ", "–°—Ä–µ–¥–Ω—è—è —à–∫–æ–ª–∞ (5-7 –∫–ª–∞—Å—Å)"),
        (50, 69): ("–°—Ä–µ–¥–Ω–µ", "–°—Ç–∞—Ä—à–∞—è —à–∫–æ–ª–∞ (8-11 –∫–ª–∞—Å—Å)"),
        (30, 49): ("–°–ª–æ–∂–Ω–æ", "–°—Ç—É–¥–µ–Ω—Ç—ã –±–∞–∫–∞–ª–∞–≤—Ä–∏–∞—Ç–∞"),
        (0, 29): ("–û—á–µ–Ω—å —Å–ª–æ–∂–Ω–æ", "–ú–∞–≥–∏—Å—Ç—Ä–∞—Ç—É—Ä–∞ / –°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç—ã"),
    }
    
    # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Ç–µ–∫—Å—Ç—É
    MIN_WORDS = 10
    MIN_SENTENCES = 1
    
    def __init__(self, language: str = "auto"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞.
        
        Args:
            language: –Ø–∑—ã–∫ —Ç–µ–∫—Å—Ç–∞ ('en', 'ru' –∏–ª–∏ 'auto' –¥–ª—è –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è)
        """
        self.language = language
        self._syllable_func = None
        
        if language == 'ru':
            self._syllable_func = count_syllables_ru
        elif language == 'en':
            self._syllable_func = count_syllables
        # –ü—Ä–∏ 'auto' —Ñ—É–Ω–∫—Ü–∏—è –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ
    
    def _get_syllable_counter(self, text: str):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≥–æ–≤."""
        if self._syllable_func:
            return self._syllable_func
        
        # –ê–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
        detected_lang = detect_language(text)
        return count_syllables_ru if detected_lang == 'ru' else count_syllables
    
    def _count_total_syllables(self, words: List[str], syllable_func) -> int:
        """–ü–æ–¥—Å—á—ë—Ç –æ–±—â–µ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≥–æ–≤."""
        return sum(syllable_func(word) for word in words)
    
    def _count_polysyllables(self, words: List[str], syllable_func) -> int:
        """–ü–æ–¥—Å—á—ë—Ç —Å–ª–æ–≤ —Å 3+ —Å–ª–æ–≥–∞–º–∏."""
        return sum(1 for word in words if syllable_func(word) >= 3)
    
    def _get_difficulty_level(self, flesch_score: float) -> tuple:
        """
        –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –ø–æ –∏–Ω–¥–µ–∫—Å—É –§–ª–µ—à–∞.
        
        Args:
            flesch_score: –ò–Ω–¥–µ–∫—Å –§–ª–µ—à–∞ (0-100)
            
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (—É—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏, —Ü–µ–ª–µ–≤–∞—è –∞—É–¥–∏—Ç–æ—Ä–∏—è)
        """
        for (low, high), (level, audience) in self.DIFFICULTY_THRESHOLDS.items():
            if low <= flesch_score <= high:
                return level, audience
        return "–ù–µ–æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ", "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
    
    def _generate_recommendations(self, 
                                   avg_sentence_length: float,
                                   avg_word_length: float,
                                   flesch_score: float,
                                   word_count: int) -> List[str]:
        """
        –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —É–ª—É—á—à–µ–Ω–∏—é —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏.
        
        Args:
            avg_sentence_length: –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            avg_word_length: –°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞
            flesch_score: –ò–Ω–¥–µ–∫—Å –§–ª–µ—à–∞
            word_count: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        """
        recommendations = []
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
        if avg_sentence_length > 25:
            recommendations.append(
                "üìù **–°–æ–∫—Ä–∞—Ç–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è:** —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç "
                f"{avg_sentence_length:.1f} —Å–ª–æ–≤ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ 20-25). "
                "–†–∞–∑–±–µ–π—Ç–µ –¥–ª–∏–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ."
            )
        elif avg_sentence_length > 20:
            recommendations.append(
                "üìù –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–µ–º–Ω–æ–≥–æ –¥–ª–∏–Ω–Ω–æ–≤–∞—Ç—ã. "
                "–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Ö —É–ø—Ä–æ—â–µ–Ω–∏—è."
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã —Å–ª–æ–≤
        if avg_word_length > 7:
            recommendations.append(
                "üìñ **–£–ø—Ä–æ—Å—Ç–∏—Ç–µ –ª–µ–∫—Å–∏–∫—É:** —Å—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞ "
                f"{avg_word_length:.1f} –±—É–∫–≤ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ 5-6). "
                "–ó–∞–º–µ–Ω–∏—Ç–µ —Å–ª–æ–∂–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –Ω–∞ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–µ —Å–∏–Ω–æ–Ω–∏–º—ã."
            )
        elif avg_word_length > 6:
            recommendations.append(
                "üìñ –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ –ø—Ä–æ—Å—Ç—ã–µ —Å–ª–æ–≤–∞."
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—â–µ–≥–æ –∏–Ω–¥–µ–∫—Å–∞
        if flesch_score < 30:
            recommendations.append(
                "‚ö†Ô∏è **–¢–µ–∫—Å—Ç –æ—á–µ–Ω—å —Å–ª–æ–∂–Ω—ã–π** –¥–ª—è –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–∞ —á–∏—Ç–∞—Ç–µ–ª–µ–π. "
                "–î–æ–±–∞–≤—å—Ç–µ –ø–æ—è—Å–Ω–µ–Ω–∏—è, –ø—Ä–∏–º–µ—Ä—ã –∏ —Ä–∞–∑–±–µ–π—Ç–µ —Å–ª–æ–∂–Ω—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏ "
                "–Ω–∞ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç—ã–µ —á–∞—Å—Ç–∏."
            )
        elif flesch_score < 50:
            recommendations.append(
                "üí° –¢–µ–∫—Å—Ç –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏. "
                "–î–ª—è –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–æ–≥–æ –∫—Ä—É–≥–∞ —á–∏—Ç–∞—Ç–µ–ª–µ–π —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É–ø—Ä–æ—Å—Ç–∏—Ç—å."
            )
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—ä—ë–º–∞ —Ç–µ–∫—Å—Ç–∞
        if word_count < 100:
            recommendations.append(
                "üìÑ –¢–µ–∫—Å—Ç –¥–æ–≤–æ–ª—å–Ω–æ –∫–æ—Ä–æ—Ç–∫–∏–π. –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ –º–æ–≥—É—Ç –±—ã—Ç—å "
                "–º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–º–∏ –¥–ª—è –∫–æ—Ä–æ—Ç–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤."
            )
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä–æ–±–ª–µ–º
        if not recommendations:
            recommendations.append(
                "‚úÖ **–û—Ç–ª–∏—á–Ω–∞—è —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç—å!** –¢–µ–∫—Å—Ç —Ö–æ—Ä–æ—à–æ —Å–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω "
                "–∏ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —à–∏—Ä–æ–∫–æ–π –∞—É–¥–∏—Ç–æ—Ä–∏–∏."
            )
        
        return recommendations
    
    def analyze(self, text: str) -> ReadabilityResult:
        """
        –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞.
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            
        Returns:
            ReadabilityResult —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏
            
        Raises:
            ValueError: –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
            
        Examples:
            >>> analyzer = TextAnalyzer()
            >>> result = analyzer.analyze("This is a simple test. It has short sentences.")
            >>> print(result.flesch_score)
            82.5
        """
        # –í–∞–ª–∏–¥–∞—Ü–∏—è –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        if not text or not text.strip():
            raise ValueError("–¢–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")
        
        # –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
        text = clean_text(text)
        
        # –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è
        sentences = tokenize_sentences(text)
        words = tokenize_words(text)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã—Ö —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π
        if len(words) < self.MIN_WORDS:
            raise ValueError(
                f"–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π: {len(words)} —Å–ª–æ–≤ "
                f"(–º–∏–Ω–∏–º—É–º {self.MIN_WORDS})"
            )
        
        if len(sentences) < self.MIN_SENTENCES:
            raise ValueError(
                f"–í —Ç–µ–∫—Å—Ç–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –º–∏–Ω–∏–º—É–º {self.MIN_SENTENCES} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ"
            )
        
        # –ü–æ–ª—É—á–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –ø–æ–¥—Å—á—ë—Ç–∞ —Å–ª–æ–≥–æ–≤
        syllable_counter = self._get_syllable_counter(text)
        
        # –ë–∞–∑–æ–≤—ã–µ –ø–æ–¥—Å—á—ë—Ç—ã
        total_chars = count_characters(words)
        total_syllables = self._count_total_syllables(words, syllable_counter)
        total_polysyllables = self._count_polysyllables(words, syllable_counter)
        
        word_count = len(words)
        sentence_count = len(sentences)
        
        # –°—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        avg_word_length = round(total_chars / word_count, 2)
        avg_sentence_length = round(word_count / sentence_count, 2)
        
        # –†–∞—Å—á—ë—Ç –∏–Ω–¥–µ–∫—Å–æ–≤
        flesch = flesch_reading_ease(word_count, sentence_count, total_syllables)
        fk_grade = flesch_kincaid_grade(word_count, sentence_count, total_syllables)
        coleman = coleman_liau_index(total_chars, word_count, sentence_count)
        ari = automated_readability_index(total_chars, word_count, sentence_count)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        difficulty, audience = self._get_difficulty_level(flesch)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        recommendations = self._generate_recommendations(
            avg_sentence_length, 
            avg_word_length, 
            flesch,
            word_count
        )
        
        return ReadabilityResult(
            text_length=len(text),
            word_count=word_count,
            sentence_count=sentence_count,
            avg_word_length=avg_word_length,
            avg_sentence_length=avg_sentence_length,
            flesch_score=flesch,
            flesch_kincaid=fk_grade,
            coleman_liau=coleman,
            ari=ari,
            difficulty_level=difficulty,
            target_audience=audience,
            recommendations=recommendations
        )
    
    def analyze_file(self, filepath: str) -> ReadabilityResult:
        """
        –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –∏–∑ —Ñ–∞–π–ª–∞.
        
        Args:
            filepath: –ü—É—Ç—å –∫ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É —Ñ–∞–π–ª—É
            
        Returns:
            ReadabilityResult —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –∞–Ω–∞–ª–∏–∑–∞
            
        Raises:
            FileNotFoundError: –ï—Å–ª–∏ —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω
            ValueError: –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º
        """
        text = read_text_file(filepath)
        return self.analyze(text)
    
    def compare_texts(self, texts: List[str], 
                      names: Optional[List[str]] = None) -> List[Dict[str, Any]]:
        """
        –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —á–∏—Ç–∞–±–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–µ–∫—Å—Ç–æ–≤.
        
        Args:
            texts: –°–ø–∏—Å–æ–∫ —Ç–µ–∫—Å—Ç–æ–≤ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            names: –ù–∞–∑–≤–∞–Ω–∏—è —Ç–µ–∫—Å—Ç–æ–≤ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
            
        Returns:
            –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        """
        if names is None:
            names = [f"–¢–µ–∫—Å—Ç {i+1}" for i in range(len(texts))]
        
        results = []
        for name, text in zip(names, texts):
            try:
                result = self.analyze(text)
                results.append({
                    'name': name,
                    'success': True,
                    'result': result.to_dict()
                })
            except ValueError as e:
                results.append({
                    'name': name,
                    'success': False,
                    'error': str(e)
                })
        
        return results